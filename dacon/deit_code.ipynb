{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa99d0c2-432e-499e-aa21-6f2064dd58cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.io import read_image\n",
    "\n",
    "import timm\n",
    "from timm.data import create_transform\n",
    "from timm.data.constants import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a3b804a-11eb-4538-bc02-17565544fd29",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 대회 공지 평가 산식\n",
    "def calc_puzzle(answer_df, submission_df):\n",
    "    # Check for missing values in submission_df\n",
    "    if submission_df.isnull().values.any():\n",
    "        raise ValueError(\"The submission dataframe contains missing values.\")\n",
    "\n",
    "    # Public or Private answer Sample and Sorting by 'ID'\n",
    "    submission_df = submission_df[submission_df.iloc[:, 0].isin(answer_df.iloc[:, 0])]\n",
    "    submission_df = submission_df.sort_values(by='ID').reset_index(drop=True)\n",
    "\n",
    "    # Check for length in submission_df\n",
    "    if len(submission_df) != len(answer_df):\n",
    "        raise ValueError(\"The submission dataframe wrong length.\")\n",
    "\n",
    "    # Convert position data to numpy arrays for efficient computation\n",
    "    answer_positions = answer_df.iloc[:, 2:].to_numpy()  # Excluding ID, img_path, and type columns\n",
    "    submission_positions = submission_df.iloc[:, 1:].to_numpy()  # Excluding ID column\n",
    "\n",
    "    # Initialize the dictionary to hold accuracies\n",
    "    accuracies = {}\n",
    "\n",
    "    # Define combinations for 2x2 and 3x3 puzzles\n",
    "    combinations_2x2 = [(i, j) for i in range(3) for j in range(3)]\n",
    "    combinations_3x3 = [(i, j) for i in range(2) for j in range(2)]\n",
    "\n",
    "    # 1x1 Puzzle Accuracy\n",
    "    accuracies['1x1'] = np.mean(answer_positions == submission_positions)\n",
    "\n",
    "    # Calculate accuracies for 2x2, 3x3, and 4x4 puzzles\n",
    "    for size in range(2, 5):  # Loop through sizes 2, 3, 4\n",
    "        correct_count = 0  # Initialize counter for correct full sub-puzzles\n",
    "        total_subpuzzles = 0\n",
    "\n",
    "        # Iterate through each sample's puzzle\n",
    "        for i in range(len(answer_df)):\n",
    "            puzzle_a = answer_positions[i].reshape(4, 4)\n",
    "            puzzle_s = submission_positions[i].reshape(4, 4)\n",
    "            combinations = combinations_2x2 if size == 2 else combinations_3x3 if size == 3 else [(0, 0)]\n",
    "\n",
    "            # Calculate the number of correct sub-puzzles for this size within a 4x4\n",
    "            for start_row, start_col in combinations:\n",
    "                rows = slice(start_row, start_row + size)\n",
    "                cols = slice(start_col, start_col + size)\n",
    "                if np.array_equal(puzzle_a[rows, cols], puzzle_s[rows, cols]):\n",
    "                    correct_count += 1\n",
    "                total_subpuzzles += 1\n",
    "\n",
    "        accuracies[f'{size}x{size}'] = correct_count / total_subpuzzles\n",
    "\n",
    "    score = (accuracies['1x1'] + accuracies['2x2'] + accuracies['3x3'] + accuracies['4x4']) / 4.\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09c1190d-d2a1-4536-9cc6-1416f301a9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사전학습된 모델 timm을 사용 \n",
    "# timm중에서 deit3_base_patch16_384라는 모델을 사용한다.\n",
    "# 24x24 패치로 나누기 때문에 4x4퍼즐을 맞춰도 영역이 일치하지 않는 문제가 발생하지 않습니다.\n",
    "# 학습 자체는 기존 Jigsaw-Vit설정을 그대로 가져와서 사용\n",
    "class Model(nn.Module):\n",
    "    # 모델 생성 및 초기화\n",
    "    # deit 모델의 일부 구성 요소를 변경하고, 선형 레이어를 추가\n",
    "    def __init__(self, mask_ratio = 0.0, pretrained = True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.mask_ratio = mask_ratio\n",
    "        self.pretrained = pretrained\n",
    "\n",
    "        deit3 = timm.create_model('deit3_base_patch16_384', pretrained = pretrained)\n",
    "\n",
    "        self.patch_embed = deit3.patch_embed\n",
    "        self.cls_token = deit3.cls_token\n",
    "        self.blocks = deit3.blocks\n",
    "        self.norm = deit3.norm\n",
    "\n",
    "        self.jigsaw = nn.Sequential(\n",
    "            nn.Linear(768, 768),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(768, 768),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(768, 24*24)\n",
    "        )\n",
    "\n",
    "    # 이미지를 무작위로 마스킹하고, 마스킹된 위치의 인덱스를 반환\n",
    "    def random_masking(self, x, mask_ratio):\n",
    "        \"\"\"\n",
    "        Perform per-sample random masking by per-sample shuffling.\n",
    "        Per-sample shuffling is done by argsort random noise.\n",
    "        x: [N, L, D], sequence\n",
    "        \"\"\"\n",
    "        N, L, D = x.shape  # batch, length, dim\n",
    "        len_keep = int(L * (1 - mask_ratio))\n",
    "    \n",
    "        # 랜덤으로 노이즈를 생성, 노이즈 기준으로 정렬, 정렬된 인덱스 중에서 첫 부분을 선택하여 마스킹 적용x\n",
    "        # 데이터의 일부를 임의로 마스킹하여 모델에 노이즈를 주어 훈련을 안정화하고 일반화 성능을 향상시키는데 사용가능\n",
    "        noise = torch.rand(N, L, device=x.device)  # noise in [0, 1]\n",
    "\n",
    "        # sort noise for each sample\n",
    "        ids_shuffle = torch.argsort(noise, dim=1)  # ascend: small is keep, large is remove\n",
    "        # target = einops.repeat(self.target, 'L -> N L', N=N)\n",
    "        # target = target.to(x.device)\n",
    "\n",
    "        # keep the first subset\n",
    "        ids_keep = ids_shuffle[:, :len_keep] # N, len_keep\n",
    "        x_masked = torch.gather(x, dim=1, index=ids_keep.unsqueeze(-1).repeat(1, 1, D))\n",
    "        target_masked = ids_keep\n",
    "\n",
    "        return x_masked, target_masked\n",
    "\n",
    "    # 예측된 결과와 마스킹된 위치의 인덱스를 반환\n",
    "    def forward(self, x):\n",
    "        x = self.patch_embed(x)\n",
    "        x, target = self.random_masking(x, self.mask_ratio)\n",
    "\n",
    "        # append cls token\n",
    "        cls_tokens = self.cls_token.expand(x.shape[0], -1, -1)\n",
    "        x = torch.cat((cls_tokens, x), dim=1)\n",
    "\n",
    "        # apply Transformer blocks\n",
    "        x = self.blocks(x)\n",
    "        x = self.norm(x)\n",
    "        x = self.jigsaw(x[:, 1:])\n",
    "        # -1은 크기 자동조절, 24x24의 사이즈로 자동 변환\n",
    "        # target은 1차원 텐서로 자동 사이즈 조절\n",
    "        return x.reshape(-1, 24*24), target.reshape(-1)\n",
    "\n",
    "    # 예측된 결과를 반환\n",
    "    def forward_test(self, x):\n",
    "        x = self.patch_embed(x)\n",
    "\n",
    "        # append cls token\n",
    "        cls_tokens = self.cls_token.expand(x.shape[0], -1, -1)\n",
    "        x = torch.cat((cls_tokens, x), dim=1)\n",
    "\n",
    "        # apply Transformer blocks\n",
    "        x = self.blocks(x)\n",
    "        x = self.norm(x)\n",
    "        x = self.jigsaw(x[:, 1:])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a24c0a38-6bb2-40a9-8264-ec5158669e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JigsawDataset(Dataset):\n",
    "    def __init__(self, df, data_path, mode='train', transform=None):\n",
    "        self.df = df\n",
    "        self.data_path = data_path\n",
    "        self.mode = mode\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    # train일 경우\n",
    "    # 이미지를 읽고, 1~16번째 순서 배열 생성\n",
    "    # 이미지를 순서에 따라 재배치\n",
    "    # 변환된 이미지 반환\n",
    "    # test일 경우\n",
    "    # 이미지를 읽고 변환이 정의되어 있다면 변환을 작용후 이미지 반환\n",
    "    # transfrom은 build_transform을 통해 train, test 각각 생성\n",
    "    def __getitem__(self, idx):\n",
    "        if self.mode == 'train':\n",
    "            row = self.df.iloc[idx]\n",
    "            image = read_image(os.path.join(self.data_path, row['img_path']))\n",
    "            shuffle_order = row[[str(i) for i in range(1, 17)]].values-1\n",
    "            image = self.reset_image(image, shuffle_order)\n",
    "            image = Image.fromarray(image)\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            return image\n",
    "        elif self.mode == 'test':\n",
    "            row = self.df.iloc[idx]\n",
    "            image = Image.open(os.path.join(self.data_path, row['img_path']))\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            return image\n",
    "\n",
    "    # 모델 입력을 위한 전처리 과정\n",
    "    # 이미지를 순서에 따라 재배열\n",
    "    def reset_image(self, image, shuffle_order):\n",
    "        # 토치에서는 채널, 높이, 넓이로 구성되어있다.\n",
    "        c, h, w = image.shape\n",
    "        # 이미지를 4x4로 만들어야하기에 4로 나눈다.\n",
    "        # 가로, 세로 길이를 4등분\n",
    "        block_h, block_w = h//4, w//4\n",
    "        # 4x4 배열의 초기화\n",
    "        image_src = [[0 for _ in range(4)] for _ in range(4)]\n",
    "        # order는 0~15\n",
    "        for idx, order in enumerate(shuffle_order):\n",
    "            h_idx, w_idx = divmod(order,4)\n",
    "            h_idx_shuffle, w_idx_shuffle = divmod(idx, 4)\n",
    "            image_src[h_idx][w_idx] = image[:, block_h * h_idx_shuffle : block_h * (h_idx_shuffle+1), block_w * w_idx_shuffle : block_w * (w_idx_shuffle+1)]\n",
    "        # 한행의 패치를 가로로 연결, 그렇게 만들어진 가로줄을 세로로 연결\n",
    "        image_src = np.concatenate([np.concatenate(image_row, -1) for image_row in image_src], -2)\n",
    "        # 토치에서는 채널이 앞에 오니까 채널을 뒤로 보내서 사용가능하게 변환\n",
    "        return image_src.transpose(1, 2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "710bfdb7-eb30-4bc9-b43a-b81ad29d841e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_transform(is_train):\n",
    "    # is_train이 True일 때, transfroms_imagenet_train을 이용해 데이터 증강을 적용\n",
    "    if is_train:\n",
    "        # this should always dispatch to transforms_imagenet_train\n",
    "        # 매개변수를 통해, 색상, jittering, auto-argumentation을 설정\n",
    "        transform = create_transform(\n",
    "            input_size = (384, 384),\n",
    "            is_training = True,\n",
    "            color_jitter = 0.3,\n",
    "            auto_augment = 'rand-m9-mstd0.5-inc1',\n",
    "            interpolation= 'bicubic',\n",
    "            re_prob= 0.25,\n",
    "            re_mode= 'pixel',\n",
    "            re_count= 1,\n",
    "        )\n",
    "        return transform\n",
    "    \n",
    "    # is_train이 False면 테스트 데이터에 대한 전처리 실행\n",
    "    # 이미지 크기 조절(사용한 모델이 384사이즈 요구), 텐서 변환, 정규화 실행 후 반환\n",
    "    t = []\n",
    "    t.append(transforms.Resize((384,384), interpolation=3))\n",
    "    t.append(transforms.ToTensor())\n",
    "    t.append(transforms.Normalize(IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD))\n",
    "    return transforms.Compose(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f267371-c6f4-41f1-b574-a293bdbba18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/train.csv')\n",
    "\n",
    "df = df.loc[:1999,:] # 수정상태 1000개 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2c36bad-e869-48e8-96b0-f38f28cf969f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df.iloc[:-600] # 수정 상태\n",
    "valid_df = df.iloc[-600:] # 수정 상태\n",
    "\n",
    "train_transform = build_transform(is_train = True)\n",
    "valid_transform = build_transform(is_train = False)\n",
    "\n",
    "train_dataset = JigsawDataset(df = train_df,\n",
    "                              data_path = './data',\n",
    "                              mode = 'train',\n",
    "                              transform = train_transform)\n",
    "valid_dataset = JigsawDataset(df = valid_df,\n",
    "                              data_path = './data',\n",
    "                              mode = 'test',\n",
    "                              transform = valid_transform)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size = 16,\n",
    "    shuffle = True\n",
    ")\n",
    "valid_dataloader = DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size = 16,\n",
    "    shuffle = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b2a0264-3407-4a3a-8a21-1f697a64b8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(mask_ratio = 0.5)\n",
    "model.to(device)\n",
    "optimizer = optim.AdamW(model.parameters(),\n",
    "                        lr=3e-5,\n",
    "                        weight_decay = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e695c21a-cdc5-49eb-a6e7-ab8f57c63fbd",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1\n",
      "[0 / 88] loss: 6.366088390350342\n",
      "Time elapsed:  2154.774600982666\n",
      "Epoch  2\n",
      "[0 / 88] loss: 6.35136079788208\n",
      "Time elapsed:  1927.8553338050842\n",
      "Epoch  3\n",
      "[0 / 88] loss: 6.30876350402832\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "for epoch in range(1, 11):\n",
    "    print('Epoch ', epoch)\n",
    "    st = time.time()\n",
    "    model.train()\n",
    "    for i, x in enumerate(train_dataloader):\n",
    "        x = x.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        preds, targets = model(x)\n",
    "\n",
    "        loss = F.cross_entropy(preds, targets)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 100 == 0: # 수정상태\n",
    "            print(f'[{i} / {len(train_dataloader)}] loss:', loss.item())\n",
    "    et = time.time()\n",
    "    print('Time elapsed: ', et-st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd748e1-71a4-4cd6-a88b-6ab67da0f060",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "outs = []\n",
    "model.eval()\n",
    "# 그라디언트 계산 비활성화로 메모리 절약\n",
    "with torch.no_grad():\n",
    "    for x in tqdm(valid_dataloader):\n",
    "        x = x.to('cuda' if torch.cuda.is_available() else 'cpu') # 수정 상태\n",
    "        # test데이터에 대한 예측 수행\n",
    "        out = model.forward_test(x)\n",
    "        # 각행 및 열에서 최댓값의 인덱스로 뱐환하고, gpu에서 cpu로 변환하는데 이번은 cpu로 계속했다.\n",
    "        out = out.argmax(dim=2).cpu().numpy()\n",
    "        outs.append(out)\n",
    "\n",
    "# 예측된 결과를 수직으로 쌓는다.\n",
    "outs = np.vstack(outs)\n",
    "valid_pred_df = valid_df.copy().drop(columns=['img_path'])\n",
    "print(outs)\n",
    "print(\"-\"*80)\n",
    "print(valid_pred_df)\n",
    "print(\"-\"*80)\n",
    "# 얘측 결과를 기반으로 퍼즐을 복원하고, 그 결과를 검증 데이터 프레인메 업데이트\n",
    "# I = total=len(valid_df)\n",
    "# idx = 데이터 프레임의 인덱스\n",
    "# row = 데이터 프레임의 1줄\n",
    "for I, (idx, row) in enumerate(tqdm(valid_pred_df.iterrows(), total=len(valid_df))):\n",
    "    # 24x24배열을 600개 만듦\n",
    "    w = outs[I].reshape(24,24)\n",
    "    # 각 행과 열의 카운트를 저장할 배열을 초기화\n",
    "    CNT_ROW = np.zeros((4,4,4), dtype=np.int32)\n",
    "    CNT_COL = np.zeros((4,4,4), dtype=np.int32)\n",
    "    # 퍼즐 순서 복원\n",
    "    for i in range(24):\n",
    "        for j in range(24):\n",
    "            ROW = i // 6\n",
    "            COL = j // 6\n",
    "            # 현 위치에서의 값\n",
    "            v = w[i][j]\n",
    "            # 행과 열에 대한 카운트에 대한 값 증가\n",
    "            CNT_ROW[ROW][COL][v // 24 // 6] += 1\n",
    "            CNT_COL[ROW][COL][v % 24 // 6] += 1\n",
    "    # 각 행과 열에서 가장 많이 등장한 값으로 퍼즐을 복원합니다\n",
    "    ans = CNT_ROW.argmax(2) * 4 + CNT_COL.argmax(2) + 1\n",
    "    ans = ans.reshape(16)\n",
    "    ans = list(map(str, ans))\n",
    "    valid_pred_df.loc[idx, '1':'16'] = ans\n",
    "score = calc_puzzle(valid_df, valid_pred_df)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2957c592-5ef9-4c12-ad5f-a3f84539f4ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
