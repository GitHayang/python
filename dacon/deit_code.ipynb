{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa99d0c2-432e-499e-aa21-6f2064dd58cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.io import read_image\n",
    "\n",
    "import timm\n",
    "from timm.data import create_transform\n",
    "from timm.data.constants import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a3b804a-11eb-4538-bc02-17565544fd29",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 대회 공지 평가 산식\n",
    "def calc_puzzle(answer_df, submission_df):\n",
    "    # Check for missing values in submission_df\n",
    "    if submission_df.isnull().values.any():\n",
    "        raise ValueError(\"The submission dataframe contains missing values.\")\n",
    "\n",
    "    # Public or Private answer Sample and Sorting by 'ID'\n",
    "    submission_df = submission_df[submission_df.iloc[:, 0].isin(answer_df.iloc[:, 0])]\n",
    "    submission_df = submission_df.sort_values(by='ID').reset_index(drop=True)\n",
    "\n",
    "    # Check for length in submission_df\n",
    "    if len(submission_df) != len(answer_df):\n",
    "        raise ValueError(\"The submission dataframe wrong length.\")\n",
    "\n",
    "    # Convert position data to numpy arrays for efficient computation\n",
    "    answer_positions = answer_df.iloc[:, 2:].to_numpy()  # Excluding ID, img_path, and type columns\n",
    "    submission_positions = submission_df.iloc[:, 1:].to_numpy()  # Excluding ID column\n",
    "\n",
    "    # Initialize the dictionary to hold accuracies\n",
    "    accuracies = {}\n",
    "\n",
    "    # Define combinations for 2x2 and 3x3 puzzles\n",
    "    combinations_2x2 = [(i, j) for i in range(3) for j in range(3)]\n",
    "    combinations_3x3 = [(i, j) for i in range(2) for j in range(2)]\n",
    "\n",
    "    # 1x1 Puzzle Accuracy\n",
    "    accuracies['1x1'] = np.mean(answer_positions == submission_positions)\n",
    "\n",
    "    # Calculate accuracies for 2x2, 3x3, and 4x4 puzzles\n",
    "    for size in range(2, 5):  # Loop through sizes 2, 3, 4\n",
    "        correct_count = 0  # Initialize counter for correct full sub-puzzles\n",
    "        total_subpuzzles = 0\n",
    "\n",
    "        # Iterate through each sample's puzzle\n",
    "        for i in range(len(answer_df)):\n",
    "            puzzle_a = answer_positions[i].reshape(4, 4)\n",
    "            puzzle_s = submission_positions[i].reshape(4, 4)\n",
    "            combinations = combinations_2x2 if size == 2 else combinations_3x3 if size == 3 else [(0, 0)]\n",
    "\n",
    "            # Calculate the number of correct sub-puzzles for this size within a 4x4\n",
    "            for start_row, start_col in combinations:\n",
    "                rows = slice(start_row, start_row + size)\n",
    "                cols = slice(start_col, start_col + size)\n",
    "                if np.array_equal(puzzle_a[rows, cols], puzzle_s[rows, cols]):\n",
    "                    correct_count += 1\n",
    "                total_subpuzzles += 1\n",
    "\n",
    "        accuracies[f'{size}x{size}'] = correct_count / total_subpuzzles\n",
    "\n",
    "    score = (accuracies['1x1'] + accuracies['2x2'] + accuracies['3x3'] + accuracies['4x4']) / 4.\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09c1190d-d2a1-4536-9cc6-1416f301a9a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 사전학습된 모델 timm을 사용 \n",
    "# timm중에서 deit3_base_patch16_384라는 모델을 사용한다.\n",
    "# 24x24 패치로 나누기 때문에 4x4퍼즐을 맞춰도 영역이 일치하지 않는 문제가 발생하지 않습니다.\n",
    "# 학습 자체는 기존 Jigsaw-Vit설정을 그대로 가져와서 사용\n",
    "class Model(nn.Module):\n",
    "    # 모델 생성 및 초기화\n",
    "    # deit 모델의 일부 구성 요소를 변경하고, 선형 레이어를 추가\n",
    "    # 모델 구성요소 변경 이외에 논문의 Jigsaw-ViT\n",
    "    def __init__(self, mask_ratio = 0.0, pretrained = True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.mask_ratio = mask_ratio\n",
    "        self.pretrained = pretrained\n",
    "\n",
    "        deit3 = timm.create_model('deit3_base_patch16_384', pretrained = pretrained)\n",
    "\n",
    "        self.patch_embed = deit3.patch_embed\n",
    "        self.cls_token = deit3.cls_token\n",
    "        self.blocks = deit3.blocks\n",
    "        self.norm = deit3.norm\n",
    "\n",
    "        self.jigsaw = nn.Sequential(\n",
    "            nn.Linear(768, 768),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(768, 768),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(768, 24*24)\n",
    "        )\n",
    "\n",
    "    # 이미지를 무작위로 마스킹하고, 마스킹된 위치의 인덱스를 반환\n",
    "    # 논문의 random-masking부분\n",
    "    def random_masking(self, x, mask_ratio):\n",
    "        \"\"\"\n",
    "        Perform per-sample random masking by per-sample shuffling.\n",
    "        Per-sample shuffling is done by argsort random noise.\n",
    "        x: [N, L, D], sequence\n",
    "        \"\"\"\n",
    "        N, L, D = x.shape  # batch, length, dim\n",
    "        len_keep = int(L * (1 - mask_ratio))\n",
    "    \n",
    "        # 랜덤으로 노이즈를 생성, 노이즈 기준으로 정렬, 정렬된 인덱스 중에서 첫 부분을 선택하여 마스킹 적용x\n",
    "        # 데이터의 일부를 임의로 마스킹하여 모델에 노이즈를 주어 훈련을 안정화하고 일반화 성능을 향상시키는데 사용가능\n",
    "        noise = torch.rand(N, L, device=x.device)  # noise in [0, 1]\n",
    "\n",
    "        # sort noise for each sample\n",
    "        ids_shuffle = torch.argsort(noise, dim=1)  # ascend: small is keep, large is remove\n",
    "        # target = einops.repeat(self.target, 'L -> N L', N=N)\n",
    "        # target = target.to(x.device)\n",
    "\n",
    "        # keep the first subset\n",
    "        ids_keep = ids_shuffle[:, :len_keep] # N, len_keep\n",
    "        x_masked = torch.gather(x, dim=1, index=ids_keep.unsqueeze(-1).repeat(1, 1, D))\n",
    "        target_masked = ids_keep\n",
    "\n",
    "        return x_masked, target_masked\n",
    "\n",
    "    # 예측된 결과와 마스킹된 위치의 인덱스를 반환\n",
    "    # 논문의 forward-jigsaw\n",
    "    # github의 forward-jigsaw + forward-cls\n",
    "    # 해당 부분이 MultiHead-Attention\n",
    "    def forward(self, x):\n",
    "        x = self.patch_embed(x)\n",
    "        x, target = self.random_masking(x, self.mask_ratio)\n",
    "\n",
    "        # append cls token\n",
    "        cls_tokens = self.cls_token.expand(x.shape[0], -1, -1)\n",
    "        x = torch.cat((cls_tokens, x), dim=1)\n",
    "\n",
    "        # apply Transformer blocks\n",
    "        x = self.blocks(x)\n",
    "        x = self.norm(x)\n",
    "        x = self.jigsaw(x[:, 1:])\n",
    "        # -1은 크기 자동조절, 24x24의 사이즈로 자동 변환\n",
    "        # target은 1차원 텐서로 자동 사이즈 조절\n",
    "        return x.reshape(-1, 24*24), target.reshape(-1)\n",
    "\n",
    "    # 예측된 결과를 반환\n",
    "    # 논문의 forward부분\n",
    "    # epochs 끝나고 실행\n",
    "    def forward_test(self, x):\n",
    "        x = self.patch_embed(x)\n",
    "\n",
    "        # append cls token\n",
    "        cls_tokens = self.cls_token.expand(x.shape[0], -1, -1)\n",
    "        x = torch.cat((cls_tokens, x), dim=1)\n",
    "\n",
    "        # apply Transformer blocks\n",
    "        x = self.blocks(x)\n",
    "        x = self.norm(x)\n",
    "        x = self.jigsaw(x[:, 1:])\n",
    "        # 패치의 값 576 => (384*384) / (16*16)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a24c0a38-6bb2-40a9-8264-ec5158669e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JigsawDataset(Dataset):\n",
    "    def __init__(self, df, data_path, mode='train', transform=None):\n",
    "        self.df = df\n",
    "        self.data_path = data_path\n",
    "        self.mode = mode\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    # train일 경우\n",
    "    # 이미지를 읽고, 1~16번째 순서 배열 생성\n",
    "    # 이미지를 순서에 따라 재배치\n",
    "    # 변환된 이미지 반환\n",
    "    # test일 경우\n",
    "    # 이미지를 읽고 변환이 정의되어 있다면 변환을 작용후 이미지 반환\n",
    "    # transfrom은 build_transform을 통해 train, test 각각 생성\n",
    "    def __getitem__(self, idx):\n",
    "        if self.mode == 'train':\n",
    "            row = self.df.iloc[idx]\n",
    "            image = read_image(os.path.join(self.data_path, row['img_path']))\n",
    "            shuffle_order = row[[str(i) for i in range(1, 17)]].values-1\n",
    "            image = self.reset_image(image, shuffle_order)\n",
    "            image = Image.fromarray(image)\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            return image\n",
    "        elif self.mode == 'test':\n",
    "            row = self.df.iloc[idx]\n",
    "            image = Image.open(os.path.join(self.data_path, row['img_path']))\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            return image\n",
    "\n",
    "    # 모델 입력을 위한 전처리 과정\n",
    "    # 이미지를 순서에 따라 재배열\n",
    "    def reset_image(self, image, shuffle_order):\n",
    "        # 토치에서는 채널, 높이, 넓이로 구성되어있다.\n",
    "        c, h, w = image.shape\n",
    "        # 이미지를 4x4로 만들어야하기에 4로 나눈다.\n",
    "        # 가로, 세로 길이를 4등분\n",
    "        block_h, block_w = h//4, w//4\n",
    "        # 4x4 배열의 초기화\n",
    "        image_src = [[0 for _ in range(4)] for _ in range(4)]\n",
    "        # order는 0~15\n",
    "        for idx, order in enumerate(shuffle_order):\n",
    "            h_idx, w_idx = divmod(order,4)\n",
    "            h_idx_shuffle, w_idx_shuffle = divmod(idx, 4)\n",
    "            image_src[h_idx][w_idx] = image[:, block_h * h_idx_shuffle : block_h * (h_idx_shuffle+1), block_w * w_idx_shuffle : block_w * (w_idx_shuffle+1)]\n",
    "        # 한행의 패치를 가로로 연결, 그렇게 만들어진 가로줄을 세로로 연결\n",
    "        image_src = np.concatenate([np.concatenate(image_row, -1) for image_row in image_src], -2)\n",
    "        # 토치에서는 채널이 앞에 오니까 채널을 뒤로 보내서 사용가능하게 변환\n",
    "        return image_src.transpose(1, 2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "710bfdb7-eb30-4bc9-b43a-b81ad29d841e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# github dataset/build-transform\n",
    "def build_transform(is_train):\n",
    "    # is_train이 True일 때, transfroms_imagenet_train을 이용해 데이터 증강을 적용\n",
    "    if is_train:\n",
    "        # this should always dispatch to transforms_imagenet_train\n",
    "        # 매개변수를 통해, 색상, jittering, auto-argumentation을 설정\n",
    "        # 384x384로 학습, 사전 학습 사용\n",
    "        transform = create_transform(\n",
    "            input_size = (384, 384),\n",
    "            is_training = True,\n",
    "            color_jitter = 0.3,\n",
    "            auto_augment = 'rand-m9-mstd0.5-inc1',\n",
    "            # 이미지 사이즈 변경시 주변 16개의 픽셀값을 계산해 이어지는 이미지의 곡선을 부드럽게 만든다.\n",
    "            # 이미지의 세부사항을 유지하며 이미지의 사이즈를 바꿀 수 있다.\n",
    "            interpolation= 'bicubic',\n",
    "            re_prob= 0.25,\n",
    "            re_mode= 'pixel',\n",
    "            re_count= 1,\n",
    "        )\n",
    "        return transform\n",
    "    \n",
    "    # is_train이 False면 테스트 데이터에 대한 전처리 실행\n",
    "    # 이미지 크기 조절(사용한 모델이 384사이즈 요구), 텐서 변환, 정규화 실행 후 반환\n",
    "    # 마지막에 compose를 사용해 데이터셋에 대한 파이프라인 생성\n",
    "    # = pytorch를 위한 파이프라인 생성\n",
    "    t = []\n",
    "    t.append(transforms.Resize((384,384), interpolation=3))\n",
    "    t.append(transforms.ToTensor())\n",
    "    t.append(transforms.Normalize(IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD))\n",
    "    return transforms.Compose(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f267371-c6f4-41f1-b574-a293bdbba18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./DATA/train.csv')\n",
    "\n",
    "df = df.loc[:1999,:] # 수정상태 1만개는 메모리 초과 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1628e99f-13e1-49f7-a8bf-6293515ed45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_1 = pd.read_csv(\"./data/test.csv\")\n",
    "test_2 = pd.read_csv(\"./data/sample_submission.csv\")\n",
    "test_df = test_1.merge(test_2, on='ID', how='inner')\n",
    "\n",
    "test_df = test_df.loc[:3000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a2c36bad-e869-48e8-96b0-f38f28cf969f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df.iloc[:900] # 수정 상태\n",
    "valid_df = df.iloc[900:] # 수정 상태\n",
    "test_df = test_df.iloc[900:] # 수정 상태\n",
    "\n",
    "train_transform = build_transform(is_train = True)\n",
    "valid_transform = build_transform(is_train = False)\n",
    "test_transform = build_transform(is_train = False)\n",
    "\n",
    "train_dataset = JigsawDataset(df = train_df,\n",
    "                              data_path = './DATA',\n",
    "                              mode = 'train',\n",
    "                              transform = train_transform)\n",
    "valid_dataset = JigsawDataset(df = valid_df,\n",
    "                              data_path = './DATA',\n",
    "                              mode = 'test',\n",
    "                              transform = valid_transform)\n",
    "\n",
    "test_dataset = JigsawDataset(df = test_df,\n",
    "                              data_path = './DATA',\n",
    "                              mode = 'test',\n",
    "                              transform = test_transform)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size = 16,\n",
    "    shuffle = True\n",
    ")\n",
    "valid_dataloader = DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size = 16,\n",
    "    shuffle = False\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size = 16,\n",
    "    shuffle = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b2a0264-3407-4a3a-8a21-1f697a64b8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(mask_ratio = 0.5)\n",
    "model.to(device)\n",
    "optimizer = optim.AdamW(model.parameters(),\n",
    "                        lr=3e-5,\n",
    "                        weight_decay = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e695c21a-cdc5-49eb-a6e7-ab8f57c63fbd",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1\n",
      "[0 / 57] loss: 6.37108039855957\n",
      "Time elapsed:  1552.8252925872803\n",
      "Epoch  2\n",
      "[0 / 57] loss: 6.354735851287842\n",
      "Time elapsed:  1621.489092350006\n",
      "Epoch  3\n",
      "[0 / 57] loss: 6.347467422485352\n",
      "Time elapsed:  1585.6633050441742\n",
      "Epoch  4\n",
      "[0 / 57] loss: 6.308975696563721\n",
      "Time elapsed:  1611.7624580860138\n",
      "Epoch  5\n",
      "[0 / 57] loss: 6.323413848876953\n",
      "Time elapsed:  1627.0431520938873\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "for epoch in range(1, 6):\n",
    "    print('Epoch ', epoch)\n",
    "    st = time.time()\n",
    "    model.train()\n",
    "    for i, x in enumerate(train_dataloader):\n",
    "        x = x.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        preds, targets = model(x)\n",
    "\n",
    "        loss = F.cross_entropy(preds, targets)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 100 == 0: # 수정상태\n",
    "            print(f'[{i} / {len(train_dataloader)}] loss:', loss.item())\n",
    "    et = time.time()\n",
    "    print('Time elapsed: ', et-st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ddd748e1-71a4-4cd6-a88b-6ab67da0f060",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b16257147104ec69273f3590ac64eeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/69 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44148db6e722440aaec0dd26363fccf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "outs = []\n",
    "model.eval()\n",
    "# 그라디언트 계산 비활성화로 메모리 절약\n",
    "with torch.no_grad():\n",
    "    for x in tqdm(valid_dataloader):\n",
    "        x = x.to('cuda' if torch.cuda.is_available() else 'cpu') # 수정 상태\n",
    "        # test데이터에 대한 예측 수행\n",
    "        out = model.forward_test(x)\n",
    "        # 각행 및 열에서 최댓값의 인덱스로 뱐환하고, gpu에서 cpu로 변환하는데 이번은 cpu로 계속했다.\n",
    "        out = out.argmax(dim=2).cpu().numpy()\n",
    "        outs.append(out)\n",
    "\n",
    "# 예측된 결과를 수직으로 쌓는다.\n",
    "outs = np.vstack(outs)\n",
    "valid_pred_df = valid_df.copy().drop(columns=['img_path'])\n",
    "# 얘측 결과를 기반으로 퍼즐을 복원하고, 그 결과를 검증 데이터 프레임에 업데이트\n",
    "# I = total = len(valid_df)\n",
    "# idx = 데이터 프레임의 인덱스\n",
    "# row = 데이터 프레임의 1줄\n",
    "for I, (idx, row) in enumerate(tqdm(valid_pred_df.iterrows(), total=len(valid_df))):\n",
    "    # 24x24배열로 만듦\n",
    "    w = outs[I].reshape(24,24)\n",
    "    # 각 행과 열의 카운트를 저장할 배열을 초기화\n",
    "    # 행, 열, 등장할 수 있는 값의 범위\n",
    "    # 추후 해당위치에서 해당 값이 얼마나 나오는지 확인을 위함\n",
    "    CNT_ROW = np.zeros((4,4,4), dtype=np.int32)\n",
    "    CNT_COL = np.zeros((4,4,4), dtype=np.int32)\n",
    "    # 퍼즐 순서 복원\n",
    "    for i in range(24):\n",
    "        for j in range(24):\n",
    "            # 0~3\n",
    "            ROW = i // 6\n",
    "            COL = j // 6\n",
    "            # 현 위치에서의 값 (현재는 24x24 배열이기 때문)\n",
    "            v = w[i][j]\n",
    "            # 세로방향이냐, 가로방향이냐에 따라 '//', '%'를 구분해서 사용\n",
    "            # 행과 열에 대한 카운트에 대한 값 증가\n",
    "            # 각 픽셀 값을 4x4로 만드는 과정\n",
    "            # 해당위치에서의 값이 얼마나 자주 등장하는지 카운트 가능\n",
    "            # 24x24 이미지를 4x4 퍼즐로 나누면 각 퍼즐은 6x6의 픽셀로 이루어집니다. \n",
    "            # 따라서 나누기 6을 통해 현재 위치의 픽셀이 해당 4x4 퍼즐에서 몇 번째 열에 속하는지를 나타낼 수 있습니다.\n",
    "            # 24로 나눈 몫으로 세로 방향의 위치를 나타내며, 추가적인 // 6을 통해 해당 행 내에서의 상대적인 위치\n",
    "            # 해당 위치의 width, height값이라서 나중에 합쳐준다.\n",
    "            CNT_ROW[ROW][COL][v // 24 // 6] += 1\n",
    "            # 열에 매핑하는 역할\n",
    "            # 24로 나눈 나머지로 가로 방향의 위치를 나타내며, 추가적인 // 6을 통해 해당 열 내에서의 상대적인 위치\n",
    "            CNT_COL[ROW][COL][v % 24 // 6] += 1\n",
    "    # 각 행과 열에서 가장 많이 등장한 값으로 퍼즐을 복원합니다\n",
    "    # 3차원 배열이라 argmax(2)\n",
    "    # 0,1,2,3을 0,4,8,12로 만들어 주고 CNT_COL을 더하여 최종적으로 0~15 값으로 만들어준다.\n",
    "    ans = CNT_ROW.argmax(2) * 4 + CNT_COL.argmax(2) + 1\n",
    "    ans = ans.reshape(16)\n",
    "    ans = list(map(str, ans))\n",
    "    valid_pred_df.loc[idx, '1':'16'] = ans\n",
    "score = calc_puzzle(valid_df, valid_pred_df)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5abf6a89-03df-4513-9a64-bf37ce6ee8f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>img_path</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>TRAIN_00900</td>\n",
       "      <td>./train/TRAIN_00900.jpg</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>TRAIN_00901</td>\n",
       "      <td>./train/TRAIN_00901.jpg</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>TRAIN_00902</td>\n",
       "      <td>./train/TRAIN_00902.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>TRAIN_00903</td>\n",
       "      <td>./train/TRAIN_00903.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>904</th>\n",
       "      <td>TRAIN_00904</td>\n",
       "      <td>./train/TRAIN_00904.jpg</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID                 img_path   1   2   3   4   5   6   7  8   9  \\\n",
       "900  TRAIN_00900  ./train/TRAIN_00900.jpg   6  16   1   8   3  13  15  5  14   \n",
       "901  TRAIN_00901  ./train/TRAIN_00901.jpg  10   8  14  15   1  16   3  7  12   \n",
       "902  TRAIN_00902  ./train/TRAIN_00902.jpg   8   4  12  13   6   3  15  2  10   \n",
       "903  TRAIN_00903  ./train/TRAIN_00903.jpg   3  15  13   4  11  14  12  1   6   \n",
       "904  TRAIN_00904  ./train/TRAIN_00904.jpg  14   1  10   4  12   2  15  3  16   \n",
       "\n",
       "     10  11  12  13  14  15  16  \n",
       "900  11   2   7   4  10   9  12  \n",
       "901   5   9  11   4   6   2  13  \n",
       "902  16  14  11   7   1   9   5  \n",
       "903  10  16   9   2   5   7   8  \n",
       "904  13   6   8  11   9   5   7  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b264262-1018-4c40-ad43-b2581acc2e18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>TRAIN_00900</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>TRAIN_00901</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>TRAIN_00902</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>TRAIN_00903</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>904</th>\n",
       "      <td>TRAIN_00904</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID   1  2   3   4   5  6  7   8  9 10 11  12  13  14 15 16\n",
       "900  TRAIN_00900   5  1   5  11   1  1  1   5  1  6  1   5   1   1  5  6\n",
       "901  TRAIN_00901  11  4  10  11   4  3  4  12  4  4  8  11   4  12  8  4\n",
       "902  TRAIN_00902   4  5   6   6  11  1  4   4  6  8  6  11  11   4  2  4\n",
       "903  TRAIN_00903   6  6   4   4   6  6  6   6  6  6  4   6   6   6  6  6\n",
       "904  TRAIN_00904   6  4   6   6  11  6  4   4  4  6  6   6   6   6  6  6"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16c67a50-e98a-42cf-80cd-1ceda6b07296",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (patch_embed): PatchEmbed(\n",
       "    (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "    (norm): Identity()\n",
       "  )\n",
       "  (blocks): Sequential(\n",
       "    (0): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (1): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (2): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (3): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (4): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (5): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (6): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (7): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (8): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (9): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (10): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (11): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "  (jigsaw): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=768, out_features=576, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a7ca10-f727-4f7b-9f1d-e66090a4c551",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea8756d-1038-49e8-83a7-72691e4c6e70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708964b1-a761-4e1e-83bd-75ffbf3ad1b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8caefc-3ef1-4d3e-b6d0-6c9708b2d89d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3a7e2242-12c2-4ead-b096-495c55022f3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0922bd3505c0492b827c77530f7f70be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/132 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f65f630d617e4fd3af80e14f5ce3227f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "outs = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for x in tqdm(test_dataloader):\n",
    "        x = x.to('cuda' if torch.cuda.is_available() else 'cpu') \n",
    "        out = model.forward_test(x)\n",
    "        out = out.argmax(dim=2).cpu().numpy()\n",
    "        outs.append(out)\n",
    "\n",
    "outs = np.vstack(outs)\n",
    "valid_pred_df = test_df.copy()\n",
    "for I, (idx, row) in enumerate(tqdm(test_df.iterrows(), total=len(test_df))):\n",
    "    w = outs[I].reshape(24,24)\n",
    "    CNT_ROW = np.zeros((4,4,4), dtype=np.int32)\n",
    "    CNT_COL = np.zeros((4,4,4), dtype=np.int32)\n",
    "    for i in range(24):\n",
    "        for j in range(24):\n",
    "            ROW = i // 6\n",
    "            COL = j // 6\n",
    "            v = w[i][j]\n",
    "            CNT_ROW[ROW][COL][v // 24 // 6] += 1\n",
    "            CNT_COL[ROW][COL][v % 24 // 6] += 1\n",
    "    ans = CNT_ROW.argmax(2) * 4 + CNT_COL.argmax(2) + 1\n",
    "    ans = ans.reshape(16)\n",
    "    ans = list(map(str, ans))\n",
    "    valid_pred_df.loc[idx, '1':'16'] = ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38e57a4-f3d7-4fbf-b56a-a64dd6c7b55f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
