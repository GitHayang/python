{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa99d0c2-432e-499e-aa21-6f2064dd58cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.io import read_image\n",
    "\n",
    "import timm\n",
    "from timm.data import create_transform\n",
    "from timm.data.constants import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a3b804a-11eb-4538-bc02-17565544fd29",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 대회 공지 평가 산식\n",
    "def calc_puzzle(answer_df, submission_df):\n",
    "    # Check for missing values in submission_df\n",
    "    if submission_df.isnull().values.any():\n",
    "        raise ValueError(\"The submission dataframe contains missing values.\")\n",
    "\n",
    "    # Public or Private answer Sample and Sorting by 'ID'\n",
    "    submission_df = submission_df[submission_df.iloc[:, 0].isin(answer_df.iloc[:, 0])]\n",
    "    submission_df = submission_df.sort_values(by='ID').reset_index(drop=True)\n",
    "\n",
    "    # Check for length in submission_df\n",
    "    if len(submission_df) != len(answer_df):\n",
    "        raise ValueError(\"The submission dataframe wrong length.\")\n",
    "\n",
    "    # Convert position data to numpy arrays for efficient computation\n",
    "    answer_positions = answer_df.iloc[:, 2:].to_numpy()  # Excluding ID, img_path, and type columns\n",
    "    submission_positions = submission_df.iloc[:, 1:].to_numpy()  # Excluding ID column\n",
    "\n",
    "    # Initialize the dictionary to hold accuracies\n",
    "    accuracies = {}\n",
    "\n",
    "    # Define combinations for 2x2 and 3x3 puzzles\n",
    "    combinations_2x2 = [(i, j) for i in range(3) for j in range(3)]\n",
    "    combinations_3x3 = [(i, j) for i in range(2) for j in range(2)]\n",
    "\n",
    "    # 1x1 Puzzle Accuracy\n",
    "    accuracies['1x1'] = np.mean(answer_positions == submission_positions)\n",
    "\n",
    "    # Calculate accuracies for 2x2, 3x3, and 4x4 puzzles\n",
    "    for size in range(2, 5):  # Loop through sizes 2, 3, 4\n",
    "        correct_count = 0  # Initialize counter for correct full sub-puzzles\n",
    "        total_subpuzzles = 0\n",
    "\n",
    "        # Iterate through each sample's puzzle\n",
    "        for i in range(len(answer_df)):\n",
    "            puzzle_a = answer_positions[i].reshape(4, 4)\n",
    "            puzzle_s = submission_positions[i].reshape(4, 4)\n",
    "            combinations = combinations_2x2 if size == 2 else combinations_3x3 if size == 3 else [(0, 0)]\n",
    "\n",
    "            # Calculate the number of correct sub-puzzles for this size within a 4x4\n",
    "            for start_row, start_col in combinations:\n",
    "                rows = slice(start_row, start_row + size)\n",
    "                cols = slice(start_col, start_col + size)\n",
    "                if np.array_equal(puzzle_a[rows, cols], puzzle_s[rows, cols]):\n",
    "                    correct_count += 1\n",
    "                total_subpuzzles += 1\n",
    "\n",
    "        accuracies[f'{size}x{size}'] = correct_count / total_subpuzzles\n",
    "\n",
    "    score = (accuracies['1x1'] + accuracies['2x2'] + accuracies['3x3'] + accuracies['4x4']) / 4.\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09c1190d-d2a1-4536-9cc6-1416f301a9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사전학습된 모델 timm을 사용 \n",
    "# timm중에서 deit3_base_patch16_384라는 모델을 사용한다.\n",
    "# 24x24 패치로 나누기 때문에 4x4퍼즐을 맞춰도 영역이 일치하지 않는 문제가 발생하지 않습니다.\n",
    "# 학습 자체는 기존 Jigsaw-Vit설정을 그대로 가져와서 사용\n",
    "class Model(nn.Module):\n",
    "    # 모델 생성 및 초기화\n",
    "    # deit 모델의 일부 구성 요소를 변경하고, 선형 레이어를 추가\n",
    "    # 모델 구성요소 변경 이외에 논문의 Jigsaw-ViT\n",
    "    def __init__(self, mask_ratio = 0.0, pretrained = True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.mask_ratio = mask_ratio\n",
    "        self.pretrained = pretrained\n",
    "\n",
    "        deit3 = timm.create_model('deit3_base_patch16_384', pretrained = pretrained)\n",
    "\n",
    "        self.patch_embed = deit3.patch_embed\n",
    "        self.cls_token = deit3.cls_token\n",
    "        self.blocks = deit3.blocks\n",
    "        self.norm = deit3.norm\n",
    "\n",
    "        self.jigsaw = nn.Sequential(\n",
    "            nn.Linear(768, 768),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(768, 768),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(768, 24*24)\n",
    "        )\n",
    "\n",
    "    # 이미지를 무작위로 마스킹하고, 마스킹된 위치의 인덱스를 반환\n",
    "    # 논문의 random-masking부분\n",
    "    def random_masking(self, x, mask_ratio):\n",
    "        \"\"\"\n",
    "        Perform per-sample random masking by per-sample shuffling.\n",
    "        Per-sample shuffling is done by argsort random noise.\n",
    "        x: [N, L, D], sequence\n",
    "        \"\"\"\n",
    "        N, L, D = x.shape  # batch, length, dim\n",
    "        len_keep = int(L * (1 - mask_ratio))\n",
    "    \n",
    "        # 랜덤으로 노이즈를 생성, 노이즈 기준으로 정렬, 정렬된 인덱스 중에서 첫 부분을 선택하여 마스킹 적용x\n",
    "        # 데이터의 일부를 임의로 마스킹하여 모델에 노이즈를 주어 훈련을 안정화하고 일반화 성능을 향상시키는데 사용가능\n",
    "        noise = torch.rand(N, L, device=x.device)  # noise in [0, 1]\n",
    "\n",
    "        # sort noise for each sample\n",
    "        ids_shuffle = torch.argsort(noise, dim=1)  # ascend: small is keep, large is remove\n",
    "        # target = einops.repeat(self.target, 'L -> N L', N=N)\n",
    "        # target = target.to(x.device)\n",
    "\n",
    "        # keep the first subset\n",
    "        ids_keep = ids_shuffle[:, :len_keep] # N, len_keep\n",
    "        x_masked = torch.gather(x, dim=1, index=ids_keep.unsqueeze(-1).repeat(1, 1, D))\n",
    "        target_masked = ids_keep\n",
    "\n",
    "        return x_masked, target_masked\n",
    "\n",
    "    # 예측된 결과와 마스킹된 위치의 인덱스를 반환\n",
    "    # 논문의 forward-jigsaw\n",
    "    # github의 forward-jigsaw + forward-cls\n",
    "    # 해당 부분이 MultiHead-Attention\n",
    "    def forward(self, x):\n",
    "        x = self.patch_embed(x)\n",
    "        x, target = self.random_masking(x, self.mask_ratio)\n",
    "\n",
    "        # append cls token\n",
    "        cls_tokens = self.cls_token.expand(x.shape[0], -1, -1)\n",
    "        x = torch.cat((cls_tokens, x), dim=1)\n",
    "\n",
    "        # apply Transformer blocks\n",
    "        x = self.blocks(x)\n",
    "        x = self.norm(x)\n",
    "        x = self.jigsaw(x[:, 1:])\n",
    "        # -1은 크기 자동조절, 24x24의 사이즈로 자동 변환\n",
    "        # target은 1차원 텐서로 자동 사이즈 조절\n",
    "        return x.reshape(-1, 24*24), target.reshape(-1)\n",
    "\n",
    "    # 예측된 결과를 반환\n",
    "    # 논문의 forward부분\n",
    "    # epochs 끝나고 실행\n",
    "    def forward_test(self, x):\n",
    "        x = self.patch_embed(x)\n",
    "\n",
    "        # append cls token\n",
    "        cls_tokens = self.cls_token.expand(x.shape[0], -1, -1)\n",
    "        x = torch.cat((cls_tokens, x), dim=1)\n",
    "\n",
    "        # apply Transformer blocks\n",
    "        x = self.blocks(x)\n",
    "        x = self.norm(x)\n",
    "        x = self.jigsaw(x[:, 1:])\n",
    "        # 패치의 값 576 => (384*384) / (16*16)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a24c0a38-6bb2-40a9-8264-ec5158669e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JigsawDataset(Dataset):\n",
    "    def __init__(self, df, data_path, mode='train', transform=None):\n",
    "        self.df = df\n",
    "        self.data_path = data_path\n",
    "        self.mode = mode\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    # train일 경우\n",
    "    # 이미지를 읽고, 1~16번째 순서 배열 생성\n",
    "    # 이미지를 순서에 따라 재배치\n",
    "    # 변환된 이미지 반환\n",
    "    # test일 경우\n",
    "    # 이미지를 읽고 변환이 정의되어 있다면 변환을 작용후 이미지 반환\n",
    "    # transfrom은 build_transform을 통해 train, test 각각 생성\n",
    "    def __getitem__(self, idx):\n",
    "        if self.mode == 'train':\n",
    "            row = self.df.iloc[idx]\n",
    "            image = read_image(os.path.join(self.data_path, row['img_path']))\n",
    "            shuffle_order = row[[str(i) for i in range(1, 17)]].values-1\n",
    "            image = self.reset_image(image, shuffle_order)\n",
    "            image = Image.fromarray(image)\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            return image\n",
    "        elif self.mode == 'test':\n",
    "            row = self.df.iloc[idx]\n",
    "            image = Image.open(os.path.join(self.data_path, row['img_path']))\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            return image\n",
    "\n",
    "    # 모델 입력을 위한 전처리 과정\n",
    "    # 이미지를 순서에 따라 재배열\n",
    "    def reset_image(self, image, shuffle_order):\n",
    "        # 토치에서는 채널, 높이, 넓이로 구성되어있다.\n",
    "        c, h, w = image.shape\n",
    "        # 이미지를 4x4로 만들어야하기에 4로 나눈다.\n",
    "        # 가로, 세로 길이를 4등분\n",
    "        block_h, block_w = h//4, w//4\n",
    "        # 4x4 배열의 초기화\n",
    "        image_src = [[0 for _ in range(4)] for _ in range(4)]\n",
    "        # order는 0~15\n",
    "        for idx, order in enumerate(shuffle_order):\n",
    "            h_idx, w_idx = divmod(order,4)\n",
    "            h_idx_shuffle, w_idx_shuffle = divmod(idx, 4)\n",
    "            image_src[h_idx][w_idx] = image[:, block_h * h_idx_shuffle : block_h * (h_idx_shuffle+1), block_w * w_idx_shuffle : block_w * (w_idx_shuffle+1)]\n",
    "        # 한행의 패치를 가로로 연결, 그렇게 만들어진 가로줄을 세로로 연결\n",
    "        image_src = np.concatenate([np.concatenate(image_row, -1) for image_row in image_src], -2)\n",
    "        # 토치에서는 채널이 앞에 오니까 채널을 뒤로 보내서 사용가능하게 변환\n",
    "        return image_src.transpose(1, 2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "710bfdb7-eb30-4bc9-b43a-b81ad29d841e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# github dataset/build-transform\n",
    "def build_transform(is_train):\n",
    "    # is_train이 True일 때, transfroms_imagenet_train을 이용해 데이터 증강을 적용\n",
    "    if is_train:\n",
    "        # this should always dispatch to transforms_imagenet_train\n",
    "        # 매개변수를 통해, 색상, jittering, auto-argumentation을 설정\n",
    "        # 384x384로 학습, 사전 학습 사용\n",
    "        transform = create_transform(\n",
    "            input_size = (384, 384),\n",
    "            is_training = True,\n",
    "            color_jitter = 0.3,\n",
    "            auto_augment = 'rand-m9-mstd0.5-inc1',\n",
    "            # 이미지 사이즈 변경시 주변 16개의 픽셀값을 계산해 이어지는 이미지의 곡선을 부드럽게 만든다.\n",
    "            # 이미지의 세부사항을 유지하며 이미지의 사이즈를 바꿀 수 있다.\n",
    "            interpolation= 'bicubic',\n",
    "            re_prob= 0.25,\n",
    "            re_mode= 'pixel',\n",
    "            re_count= 1,\n",
    "        )\n",
    "        return transform\n",
    "    \n",
    "    # is_train이 False면 테스트 데이터에 대한 전처리 실행\n",
    "    # 이미지 크기 조절(사용한 모델이 384사이즈 요구), 텐서 변환, 정규화 실행 후 반환\n",
    "    # 마지막에 compose를 사용해 데이터셋에 대한 파이프라인 생성\n",
    "    # = pytorch를 위한 파이프라인 생성\n",
    "    t = []\n",
    "    t.append(transforms.Resize((384,384), interpolation=3))\n",
    "    t.append(transforms.ToTensor())\n",
    "    t.append(transforms.Normalize(IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD))\n",
    "    return transforms.Compose(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f267371-c6f4-41f1-b574-a293bdbba18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./DATA/train.csv')\n",
    "\n",
    "# df = df.loc[:69999,:] # 수정상태 1만개는 메모리 초과 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03327fa8-c065-4ada-a9ed-c8ffa64d458e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2c36bad-e869-48e8-96b0-f38f28cf969f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df.iloc[:60000] # 수정 상태\n",
    "valid_df = df.iloc[60000:] # 수정 상태\n",
    "\n",
    "train_transform = build_transform(is_train = True)\n",
    "valid_transform = build_transform(is_train = False)\n",
    "\n",
    "train_dataset = JigsawDataset(df = train_df,\n",
    "                              data_path = './DATA',\n",
    "                              mode = 'train',\n",
    "                              transform = train_transform)\n",
    "valid_dataset = JigsawDataset(df = valid_df,\n",
    "                              data_path = './DATA',\n",
    "                              mode = 'test',\n",
    "                              transform = valid_transform)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size = 16,\n",
    "    shuffle = True\n",
    ")\n",
    "valid_dataloader = DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size = 16,\n",
    "    shuffle = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b2a0264-3407-4a3a-8a21-1f697a64b8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(mask_ratio = 0.5)\n",
    "model.to(device)\n",
    "optimizer = optim.AdamW(model.parameters(),\n",
    "                        lr=3e-5,\n",
    "                        weight_decay = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e695c21a-cdc5-49eb-a6e7-ab8f57c63fbd",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1\n",
      "[0 / 3750] loss: 6.367685794830322\n",
      "[100 / 3750] loss: 6.345451354980469\n",
      "[200 / 3750] loss: 6.286317348480225\n",
      "[300 / 3750] loss: 6.275665760040283\n",
      "[400 / 3750] loss: 6.289939880371094\n",
      "[500 / 3750] loss: 6.260000228881836\n",
      "[600 / 3750] loss: 6.193700790405273\n",
      "[700 / 3750] loss: 6.180169105529785\n",
      "[800 / 3750] loss: 6.165082931518555\n",
      "[900 / 3750] loss: 6.134222030639648\n",
      "[1000 / 3750] loss: 6.089300155639648\n",
      "[1100 / 3750] loss: 6.149042129516602\n",
      "[1200 / 3750] loss: 6.226722240447998\n",
      "[1300 / 3750] loss: 6.049089431762695\n",
      "[1400 / 3750] loss: 5.961428642272949\n",
      "[1500 / 3750] loss: 6.015570163726807\n",
      "[1600 / 3750] loss: 6.049179553985596\n",
      "[1700 / 3750] loss: 5.956174850463867\n",
      "[1800 / 3750] loss: 5.970483779907227\n",
      "[1900 / 3750] loss: 5.723903656005859\n",
      "[2000 / 3750] loss: 5.980627059936523\n",
      "[2100 / 3750] loss: 5.936081409454346\n",
      "[2200 / 3750] loss: 5.817219257354736\n",
      "[2300 / 3750] loss: 5.822732448577881\n",
      "[2400 / 3750] loss: 5.897490978240967\n",
      "[2500 / 3750] loss: 5.95426607131958\n",
      "[2600 / 3750] loss: 5.672781944274902\n",
      "[2700 / 3750] loss: 5.92483377456665\n",
      "[2800 / 3750] loss: 5.794460773468018\n",
      "[2900 / 3750] loss: 5.967937469482422\n",
      "[3000 / 3750] loss: 5.803365230560303\n",
      "[3100 / 3750] loss: 5.7684550285339355\n",
      "[3200 / 3750] loss: 5.709167003631592\n",
      "[3300 / 3750] loss: 5.825376510620117\n",
      "[3400 / 3750] loss: 5.653412342071533\n",
      "[3500 / 3750] loss: 5.732692718505859\n",
      "[3600 / 3750] loss: 5.8326263427734375\n",
      "[3700 / 3750] loss: 5.733168125152588\n",
      "Time elapsed:  1729.179735660553\n",
      "Epoch  2\n",
      "[0 / 3750] loss: 5.791289806365967\n",
      "[100 / 3750] loss: 5.729578495025635\n",
      "[200 / 3750] loss: 5.810070514678955\n",
      "[300 / 3750] loss: 5.771618366241455\n",
      "[400 / 3750] loss: 5.693843841552734\n",
      "[500 / 3750] loss: 5.824010372161865\n",
      "[600 / 3750] loss: 5.742704391479492\n",
      "[700 / 3750] loss: 5.598124027252197\n",
      "[800 / 3750] loss: 5.693719863891602\n",
      "[900 / 3750] loss: 5.555822372436523\n",
      "[1000 / 3750] loss: 5.8097052574157715\n",
      "[1100 / 3750] loss: 5.647336006164551\n",
      "[1200 / 3750] loss: 5.7672834396362305\n",
      "[1300 / 3750] loss: 5.575984001159668\n",
      "[1400 / 3750] loss: 5.51384162902832\n",
      "[1500 / 3750] loss: 5.713808059692383\n",
      "[1600 / 3750] loss: 5.517626762390137\n",
      "[1700 / 3750] loss: 5.551212310791016\n",
      "[1800 / 3750] loss: 5.778776168823242\n",
      "[1900 / 3750] loss: 5.726001262664795\n",
      "[2000 / 3750] loss: 5.613247871398926\n",
      "[2100 / 3750] loss: 5.667630672454834\n",
      "[2200 / 3750] loss: 5.523679256439209\n",
      "[2300 / 3750] loss: 5.467015743255615\n",
      "[2400 / 3750] loss: 5.362192630767822\n",
      "[2500 / 3750] loss: 5.437655925750732\n",
      "[2600 / 3750] loss: 5.522118091583252\n",
      "[2700 / 3750] loss: 5.7096967697143555\n",
      "[2800 / 3750] loss: 5.617532730102539\n",
      "[2900 / 3750] loss: 5.557561874389648\n",
      "[3000 / 3750] loss: 5.788438320159912\n",
      "[3100 / 3750] loss: 5.777623653411865\n",
      "[3200 / 3750] loss: 5.662265300750732\n",
      "[3300 / 3750] loss: 5.753416061401367\n",
      "[3400 / 3750] loss: 5.557539463043213\n",
      "[3500 / 3750] loss: 5.679182529449463\n",
      "[3600 / 3750] loss: 5.3802995681762695\n",
      "[3700 / 3750] loss: 5.61341667175293\n",
      "Time elapsed:  1731.2245786190033\n",
      "Epoch  3\n",
      "[0 / 3750] loss: 5.38502311706543\n",
      "[100 / 3750] loss: 5.468972206115723\n",
      "[200 / 3750] loss: 5.753122329711914\n",
      "[300 / 3750] loss: 5.523269176483154\n",
      "[400 / 3750] loss: 5.7462263107299805\n",
      "[500 / 3750] loss: 5.672600746154785\n",
      "[600 / 3750] loss: 5.396186351776123\n",
      "[700 / 3750] loss: 5.616811752319336\n",
      "[800 / 3750] loss: 5.338422775268555\n",
      "[900 / 3750] loss: 5.8212456703186035\n",
      "[1000 / 3750] loss: 5.702873706817627\n",
      "[1100 / 3750] loss: 5.557956695556641\n",
      "[1200 / 3750] loss: 5.593560218811035\n",
      "[1300 / 3750] loss: 5.51093053817749\n",
      "[1400 / 3750] loss: 5.6837568283081055\n",
      "[1500 / 3750] loss: 5.574722766876221\n",
      "[1600 / 3750] loss: 5.518011569976807\n",
      "[1700 / 3750] loss: 5.678083419799805\n",
      "[1800 / 3750] loss: 5.602938175201416\n",
      "[1900 / 3750] loss: 5.622918605804443\n",
      "[2000 / 3750] loss: 5.450636386871338\n",
      "[2100 / 3750] loss: 5.503049373626709\n",
      "[2200 / 3750] loss: 5.9055399894714355\n",
      "[2300 / 3750] loss: 5.376780033111572\n",
      "[2400 / 3750] loss: 5.398456573486328\n",
      "[2500 / 3750] loss: 5.430746078491211\n",
      "[2600 / 3750] loss: 5.471187591552734\n",
      "[2700 / 3750] loss: 5.573073387145996\n",
      "[2800 / 3750] loss: 5.392107963562012\n",
      "[2900 / 3750] loss: 5.342803001403809\n",
      "[3000 / 3750] loss: 5.704660892486572\n",
      "[3100 / 3750] loss: 5.474200248718262\n",
      "[3200 / 3750] loss: 5.615335464477539\n",
      "[3300 / 3750] loss: 5.345427989959717\n",
      "[3400 / 3750] loss: 5.558011054992676\n",
      "[3500 / 3750] loss: 5.447612762451172\n",
      "[3600 / 3750] loss: 5.278666973114014\n",
      "[3700 / 3750] loss: 5.447267532348633\n",
      "Time elapsed:  1731.67040681839\n",
      "Epoch  4\n",
      "[0 / 3750] loss: 5.388357162475586\n",
      "[100 / 3750] loss: 5.466856479644775\n",
      "[200 / 3750] loss: 5.493103504180908\n",
      "[300 / 3750] loss: 5.414018630981445\n",
      "[400 / 3750] loss: 5.4316911697387695\n",
      "[500 / 3750] loss: 5.359649658203125\n",
      "[600 / 3750] loss: 5.58657169342041\n",
      "[700 / 3750] loss: 5.224535942077637\n",
      "[800 / 3750] loss: 5.239721775054932\n",
      "[900 / 3750] loss: 5.681421279907227\n",
      "[1000 / 3750] loss: 5.307397842407227\n",
      "[1100 / 3750] loss: 5.588971138000488\n",
      "[1200 / 3750] loss: 5.410254955291748\n",
      "[1300 / 3750] loss: 5.430959701538086\n",
      "[1400 / 3750] loss: 5.328067302703857\n",
      "[1500 / 3750] loss: 5.2543535232543945\n",
      "[1600 / 3750] loss: 5.235752582550049\n",
      "[1700 / 3750] loss: 5.64728307723999\n",
      "[1800 / 3750] loss: 5.472273826599121\n",
      "[1900 / 3750] loss: 5.460878849029541\n",
      "[2000 / 3750] loss: 5.366239547729492\n",
      "[2100 / 3750] loss: 5.503777503967285\n",
      "[2200 / 3750] loss: 5.45339298248291\n",
      "[2300 / 3750] loss: 5.277037143707275\n",
      "[2400 / 3750] loss: 5.440203666687012\n",
      "[2500 / 3750] loss: 5.351163864135742\n",
      "[2600 / 3750] loss: 5.609984874725342\n",
      "[2700 / 3750] loss: 5.294345855712891\n",
      "[2800 / 3750] loss: 5.14751672744751\n",
      "[2900 / 3750] loss: 5.233564376831055\n",
      "[3000 / 3750] loss: 5.204432010650635\n",
      "[3100 / 3750] loss: 5.279763698577881\n",
      "[3200 / 3750] loss: 5.475767612457275\n",
      "[3300 / 3750] loss: 5.415925979614258\n",
      "[3400 / 3750] loss: 5.39277458190918\n",
      "[3500 / 3750] loss: 5.254572868347168\n",
      "[3600 / 3750] loss: 5.389551162719727\n",
      "[3700 / 3750] loss: 5.454258918762207\n",
      "Time elapsed:  1731.5734372138977\n",
      "Epoch  5\n",
      "[0 / 3750] loss: 5.306097984313965\n",
      "[100 / 3750] loss: 5.102594375610352\n",
      "[200 / 3750] loss: 5.343583583831787\n",
      "[300 / 3750] loss: 5.255415439605713\n",
      "[400 / 3750] loss: 5.356490135192871\n",
      "[500 / 3750] loss: 5.2786712646484375\n",
      "[600 / 3750] loss: 5.31608772277832\n",
      "[700 / 3750] loss: 5.169179439544678\n",
      "[800 / 3750] loss: 5.263408660888672\n",
      "[900 / 3750] loss: 5.2681965827941895\n",
      "[1000 / 3750] loss: 5.574782371520996\n",
      "[1100 / 3750] loss: 5.270607948303223\n",
      "[1200 / 3750] loss: 5.136940956115723\n",
      "[1300 / 3750] loss: 5.1405158042907715\n",
      "[1400 / 3750] loss: 5.576771259307861\n",
      "[1500 / 3750] loss: 5.299620151519775\n",
      "[1600 / 3750] loss: 5.309848785400391\n",
      "[1700 / 3750] loss: 5.169677257537842\n",
      "[1800 / 3750] loss: 5.094132900238037\n",
      "[1900 / 3750] loss: 5.386681079864502\n",
      "[2000 / 3750] loss: 5.373395919799805\n",
      "[2100 / 3750] loss: 5.181089401245117\n",
      "[2200 / 3750] loss: 5.374081611633301\n",
      "[2300 / 3750] loss: 5.263910293579102\n",
      "[2400 / 3750] loss: 5.116726875305176\n",
      "[2500 / 3750] loss: 5.225239276885986\n",
      "[2600 / 3750] loss: 5.07698917388916\n",
      "[2700 / 3750] loss: 5.143822193145752\n",
      "[2800 / 3750] loss: 5.5005645751953125\n",
      "[2900 / 3750] loss: 5.11012077331543\n",
      "[3000 / 3750] loss: 5.263050079345703\n",
      "[3100 / 3750] loss: 5.078665256500244\n",
      "[3200 / 3750] loss: 4.95816707611084\n",
      "[3300 / 3750] loss: 5.436925411224365\n",
      "[3400 / 3750] loss: 5.379616737365723\n",
      "[3500 / 3750] loss: 5.414550304412842\n",
      "[3600 / 3750] loss: 5.305631160736084\n",
      "[3700 / 3750] loss: 5.341180801391602\n",
      "Time elapsed:  1731.5496108531952\n",
      "Epoch  6\n",
      "[0 / 3750] loss: 5.145658493041992\n",
      "[100 / 3750] loss: 5.131507873535156\n",
      "[200 / 3750] loss: 5.178689479827881\n",
      "[300 / 3750] loss: 5.306429862976074\n",
      "[400 / 3750] loss: 5.088155269622803\n",
      "[500 / 3750] loss: 4.98236608505249\n",
      "[600 / 3750] loss: 5.4520583152771\n",
      "[700 / 3750] loss: 5.25507116317749\n",
      "[800 / 3750] loss: 5.027114391326904\n",
      "[900 / 3750] loss: 5.067298889160156\n",
      "[1000 / 3750] loss: 5.006021499633789\n",
      "[1100 / 3750] loss: 5.070459842681885\n",
      "[1200 / 3750] loss: 5.358341693878174\n",
      "[1300 / 3750] loss: 5.377049446105957\n",
      "[1400 / 3750] loss: 5.24244499206543\n",
      "[1500 / 3750] loss: 5.285545349121094\n",
      "[1600 / 3750] loss: 5.140480995178223\n",
      "[1700 / 3750] loss: 5.3087992668151855\n",
      "[1800 / 3750] loss: 5.140219211578369\n",
      "[1900 / 3750] loss: 4.935612201690674\n",
      "[2000 / 3750] loss: 5.031859397888184\n",
      "[2100 / 3750] loss: 5.35434627532959\n",
      "[2200 / 3750] loss: 5.222390651702881\n",
      "[2300 / 3750] loss: 5.30339241027832\n",
      "[2400 / 3750] loss: 5.215293884277344\n",
      "[2500 / 3750] loss: 5.166662216186523\n",
      "[2600 / 3750] loss: 5.240720748901367\n",
      "[2700 / 3750] loss: 5.065115451812744\n",
      "[2800 / 3750] loss: 5.196621417999268\n",
      "[2900 / 3750] loss: 5.235779285430908\n",
      "[3000 / 3750] loss: 5.257913589477539\n",
      "[3100 / 3750] loss: 5.10081672668457\n",
      "[3200 / 3750] loss: 5.339113235473633\n",
      "[3300 / 3750] loss: 5.346170425415039\n",
      "[3400 / 3750] loss: 4.940732002258301\n",
      "[3500 / 3750] loss: 5.26818323135376\n",
      "[3600 / 3750] loss: 5.315310955047607\n",
      "[3700 / 3750] loss: 5.102365493774414\n",
      "Time elapsed:  1731.4228127002716\n",
      "Epoch  7\n",
      "[0 / 3750] loss: 4.812349319458008\n",
      "[100 / 3750] loss: 5.245977401733398\n",
      "[200 / 3750] loss: 5.128088474273682\n",
      "[300 / 3750] loss: 4.944119930267334\n",
      "[400 / 3750] loss: 5.095561504364014\n",
      "[500 / 3750] loss: 5.346410751342773\n",
      "[600 / 3750] loss: 5.080865859985352\n",
      "[700 / 3750] loss: 4.820990562438965\n",
      "[800 / 3750] loss: 5.116995811462402\n",
      "[900 / 3750] loss: 5.062898635864258\n",
      "[1000 / 3750] loss: 5.109663963317871\n",
      "[1100 / 3750] loss: 5.0249810218811035\n",
      "[1200 / 3750] loss: 5.076667785644531\n",
      "[1300 / 3750] loss: 5.172316074371338\n",
      "[1400 / 3750] loss: 5.300069332122803\n",
      "[1500 / 3750] loss: 4.915903568267822\n",
      "[1600 / 3750] loss: 4.922183513641357\n",
      "[1700 / 3750] loss: 4.880753040313721\n",
      "[1800 / 3750] loss: 5.154296398162842\n",
      "[1900 / 3750] loss: 5.396816730499268\n",
      "[2000 / 3750] loss: 4.992793560028076\n",
      "[2100 / 3750] loss: 4.992465019226074\n",
      "[2200 / 3750] loss: 5.126382827758789\n",
      "[2300 / 3750] loss: 4.877295970916748\n",
      "[2400 / 3750] loss: 5.147919654846191\n",
      "[2500 / 3750] loss: 5.036077499389648\n",
      "[2600 / 3750] loss: 5.657309055328369\n",
      "[2700 / 3750] loss: 5.360766887664795\n",
      "[2800 / 3750] loss: 5.02723503112793\n",
      "[2900 / 3750] loss: 5.083922386169434\n",
      "[3000 / 3750] loss: 5.206126689910889\n",
      "[3100 / 3750] loss: 4.978564262390137\n",
      "[3200 / 3750] loss: 5.147951126098633\n",
      "[3300 / 3750] loss: 5.305734634399414\n",
      "[3400 / 3750] loss: 5.23408317565918\n",
      "[3500 / 3750] loss: 5.1151227951049805\n",
      "[3600 / 3750] loss: 5.0810394287109375\n",
      "[3700 / 3750] loss: 5.0965399742126465\n",
      "Time elapsed:  1732.0294399261475\n",
      "Epoch  8\n",
      "[0 / 3750] loss: 5.101911544799805\n",
      "[100 / 3750] loss: 4.922445297241211\n",
      "[200 / 3750] loss: 5.158760070800781\n",
      "[300 / 3750] loss: 5.33256721496582\n",
      "[400 / 3750] loss: 5.066802501678467\n",
      "[500 / 3750] loss: 5.235684871673584\n",
      "[600 / 3750] loss: 5.533644676208496\n",
      "[700 / 3750] loss: 5.203920364379883\n",
      "[800 / 3750] loss: 5.110532283782959\n",
      "[900 / 3750] loss: 4.79041862487793\n",
      "[1000 / 3750] loss: 4.940441131591797\n",
      "[1100 / 3750] loss: 5.1720170974731445\n",
      "[1200 / 3750] loss: 5.045548915863037\n",
      "[1300 / 3750] loss: 5.084238052368164\n",
      "[1400 / 3750] loss: 4.876823425292969\n",
      "[1500 / 3750] loss: 4.914582252502441\n",
      "[1600 / 3750] loss: 4.983191013336182\n",
      "[1700 / 3750] loss: 4.975214004516602\n",
      "[1800 / 3750] loss: 5.257071495056152\n",
      "[1900 / 3750] loss: 5.328537940979004\n",
      "[2000 / 3750] loss: 4.770566940307617\n",
      "[2100 / 3750] loss: 4.881779193878174\n",
      "[2200 / 3750] loss: 4.965418338775635\n",
      "[2300 / 3750] loss: 5.079151153564453\n",
      "[2400 / 3750] loss: 5.395276069641113\n",
      "[2500 / 3750] loss: 5.403190612792969\n",
      "[2600 / 3750] loss: 5.1267805099487305\n",
      "[2700 / 3750] loss: 5.072781085968018\n",
      "[2800 / 3750] loss: 5.168839454650879\n",
      "[2900 / 3750] loss: 5.241395473480225\n",
      "[3000 / 3750] loss: 4.920511245727539\n",
      "[3100 / 3750] loss: 5.4393157958984375\n",
      "[3200 / 3750] loss: 4.94371223449707\n",
      "[3300 / 3750] loss: 5.287963390350342\n",
      "[3400 / 3750] loss: 5.037076950073242\n",
      "[3500 / 3750] loss: 4.874755382537842\n",
      "[3600 / 3750] loss: 5.1185784339904785\n",
      "[3700 / 3750] loss: 5.059713840484619\n",
      "Time elapsed:  1732.0400171279907\n",
      "Epoch  9\n",
      "[0 / 3750] loss: 5.128051280975342\n",
      "[100 / 3750] loss: 5.501813888549805\n",
      "[200 / 3750] loss: 4.99272346496582\n",
      "[300 / 3750] loss: 4.896218299865723\n",
      "[400 / 3750] loss: 4.964498519897461\n",
      "[500 / 3750] loss: 5.094793319702148\n",
      "[600 / 3750] loss: 5.290191173553467\n",
      "[700 / 3750] loss: 5.194211959838867\n",
      "[800 / 3750] loss: 5.034204483032227\n",
      "[900 / 3750] loss: 5.085633277893066\n",
      "[1000 / 3750] loss: 5.113471984863281\n",
      "[1100 / 3750] loss: 5.142341136932373\n",
      "[1200 / 3750] loss: 4.904870986938477\n",
      "[1300 / 3750] loss: 5.129537582397461\n",
      "[1400 / 3750] loss: 5.097348213195801\n",
      "[1500 / 3750] loss: 4.968010902404785\n",
      "[1600 / 3750] loss: 4.975275039672852\n",
      "[1700 / 3750] loss: 5.2911295890808105\n",
      "[1800 / 3750] loss: 5.015691757202148\n",
      "[1900 / 3750] loss: 4.872723579406738\n",
      "[2000 / 3750] loss: 4.885231971740723\n",
      "[2100 / 3750] loss: 5.0799455642700195\n",
      "[2200 / 3750] loss: 4.719336032867432\n",
      "[2300 / 3750] loss: 4.849908351898193\n",
      "[2400 / 3750] loss: 4.959054470062256\n",
      "[2500 / 3750] loss: 5.008782386779785\n",
      "[2600 / 3750] loss: 5.160638809204102\n",
      "[2700 / 3750] loss: 5.2417073249816895\n",
      "[2800 / 3750] loss: 4.697564601898193\n",
      "[2900 / 3750] loss: 5.114188194274902\n",
      "[3000 / 3750] loss: 4.864614963531494\n",
      "[3100 / 3750] loss: 5.205752372741699\n",
      "[3200 / 3750] loss: 4.998476982116699\n",
      "[3300 / 3750] loss: 4.998146057128906\n",
      "[3400 / 3750] loss: 4.988931655883789\n",
      "[3500 / 3750] loss: 5.072370529174805\n",
      "[3600 / 3750] loss: 4.9525146484375\n",
      "[3700 / 3750] loss: 4.923381805419922\n",
      "Time elapsed:  1732.2959883213043\n",
      "Epoch  10\n",
      "[0 / 3750] loss: 5.35508918762207\n",
      "[100 / 3750] loss: 4.862406253814697\n",
      "[200 / 3750] loss: 4.5772271156311035\n",
      "[300 / 3750] loss: 5.099789619445801\n",
      "[400 / 3750] loss: 4.707662105560303\n",
      "[500 / 3750] loss: 5.22762393951416\n",
      "[600 / 3750] loss: 5.111626625061035\n",
      "[700 / 3750] loss: 5.0428056716918945\n",
      "[800 / 3750] loss: 5.264986038208008\n",
      "[900 / 3750] loss: 4.646154880523682\n",
      "[1000 / 3750] loss: 5.082892417907715\n",
      "[1100 / 3750] loss: 5.023272514343262\n",
      "[1200 / 3750] loss: 5.107217311859131\n",
      "[1300 / 3750] loss: 4.747008800506592\n",
      "[1400 / 3750] loss: 4.58384370803833\n",
      "[1500 / 3750] loss: 4.945825099945068\n",
      "[1600 / 3750] loss: 4.923468112945557\n",
      "[1700 / 3750] loss: 5.337213516235352\n",
      "[1800 / 3750] loss: 4.72953987121582\n",
      "[1900 / 3750] loss: 5.11329984664917\n",
      "[2000 / 3750] loss: 4.964849472045898\n",
      "[2100 / 3750] loss: 5.160804271697998\n",
      "[2200 / 3750] loss: 5.080637454986572\n",
      "[2300 / 3750] loss: 5.095403671264648\n",
      "[2400 / 3750] loss: 4.911584377288818\n",
      "[2500 / 3750] loss: 5.099586009979248\n",
      "[2600 / 3750] loss: 4.69123649597168\n",
      "[2700 / 3750] loss: 5.079076766967773\n",
      "[2800 / 3750] loss: 4.938878059387207\n",
      "[2900 / 3750] loss: 4.977903366088867\n",
      "[3000 / 3750] loss: 5.066887378692627\n",
      "[3100 / 3750] loss: 5.243936061859131\n",
      "[3200 / 3750] loss: 4.812326908111572\n",
      "[3300 / 3750] loss: 4.931684970855713\n",
      "[3400 / 3750] loss: 4.862717151641846\n",
      "[3500 / 3750] loss: 4.933081150054932\n",
      "[3600 / 3750] loss: 4.934493064880371\n",
      "[3700 / 3750] loss: 4.808538436889648\n",
      "Time elapsed:  1732.480946779251\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "for epoch in range(1, 11):\n",
    "    print('Epoch ', epoch)\n",
    "    st = time.time()\n",
    "    model.train()\n",
    "    for i, x in enumerate(train_dataloader):\n",
    "        x = x.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        preds, targets = model(x)\n",
    "\n",
    "        loss = F.cross_entropy(preds, targets)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 100 == 0: # 수정상태\n",
    "            print(f'[{i} / {len(train_dataloader)}] loss:', loss.item())\n",
    "    et = time.time()\n",
    "    print('Time elapsed: ', et-st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ddd748e1-71a4-4cd6-a88b-6ab67da0f060",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c20a55bfd7e74612a81a8a5dd7882a71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f036b9ff8ba547859add6dd070639d86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "outs = []\n",
    "model.eval()\n",
    "# 그라디언트 계산 비활성화로 메모리 절약\n",
    "with torch.no_grad():\n",
    "    for x in tqdm(valid_dataloader):\n",
    "        x = x.to('cuda' if torch.cuda.is_available() else 'cpu') # 수정 상태\n",
    "        # test데이터에 대한 예측 수행\n",
    "        out = model.forward_test(x)\n",
    "        # 각행 및 열에서 최댓값의 인덱스로 뱐환하고, gpu에서 cpu로 변환하는데 이번은 cpu로 계속했다.\n",
    "        out = out.argmax(dim=2).cpu().numpy()\n",
    "        outs.append(out)\n",
    "\n",
    "# 예측된 결과를 수직으로 쌓는다.\n",
    "outs = np.vstack(outs)\n",
    "valid_pred_df = valid_df.copy().drop(columns=['img_path'])\n",
    "# 얘측 결과를 기반으로 퍼즐을 복원하고, 그 결과를 검증 데이터 프레임에 업데이트\n",
    "# I = total = len(valid_df)\n",
    "# idx = 데이터 프레임의 인덱스\n",
    "# row = 데이터 프레임의 1줄\n",
    "for I, (idx, row) in enumerate(tqdm(valid_pred_df.iterrows(), total=len(valid_df))):\n",
    "    # 24x24배열로 만듦\n",
    "    w = outs[I].reshape(24,24)\n",
    "    # 각 행과 열의 카운트를 저장할 배열을 초기화\n",
    "    # rgb에 배치값이다 (4개의 조각, 4개의 행, 4개의 열)\n",
    "    CNT_ROW = np.zeros((4,4,4), dtype=np.int32)\n",
    "    CNT_COL = np.zeros((4,4,4), dtype=np.int32)\n",
    "    # 퍼즐 순서 복원\n",
    "    for i in range(24):\n",
    "        for j in range(24):\n",
    "            # 0~3\n",
    "            ROW = i // 6\n",
    "            COL = j // 6\n",
    "            # 현 위치에서의 값 (현재는 24x24 배열이기 때문)\n",
    "            v = w[i][j]\n",
    "            # 양쪽다 //나 %로 써도 가능\n",
    "            # 행과 열에 대한 카운트에 대한 값 증가\n",
    "            # 각 픽셀 값을 4x4로 만드는 과정\n",
    "            # (i,j)의 위치값이 어디인지 찾는 연산\n",
    "            # 이로인해 24x24 이미지의 각 픽셀이 4x4 퍼즐의 행과 열에 매핑되며, \n",
    "            # 해당위치에서의 값이 얼마나 자주 등장하는지 카운트 가능\n",
    "            # 24로 나누면 행이 결정되고 6으로 나누면 해당 행에서 상대적인 위치가 결정된다\n",
    "            # 24x24 이미지를 4x4 퍼즐로 나누면 각 퍼즐은 6x6의 픽셀로 이루어집니다. \n",
    "            # 따라서 나누기 6을 통해 현재 위치의 픽셀이 해당 4x4 퍼즐에서 몇 번째 열에 속하는지를 나타낼 수 있습니다.\n",
    "            CNT_ROW[ROW][COL][v // 24 // 6] += 1\n",
    "            # 열에 매핑하는 역할\n",
    "            # 나머지 값은 현재 위치가 24의 배수가 아닌 경우, 현재 위치가 24의 배수로부터 얼마나 떨어져 있는지를 나타냅니다. \n",
    "            # 이 값을 6으로 나누면 0부터 5까지의 범위의 값을 얻게 되는데, 이것이 4x4 퍼즐 내에서의 상대적인 행 위치를 나타내게 됩니다.\n",
    "            CNT_COL[ROW][COL][v % 24 // 6] += 1\n",
    "    # 각 행과 열에서 가장 많이 등장한 값으로 퍼즐을 복원합니다\n",
    "    # 3차원 배열이라 argmax(2)\n",
    "    # 0,1,2,3을 0,4,8,12로 만들어 준고 CNT_COL을 더하여 최종적으로 0~16 값으로 만들어준다.\n",
    "    ans = CNT_ROW.argmax(2) * 4 + CNT_COL.argmax(2) + 1\n",
    "    ans = ans.reshape(16)\n",
    "    ans = list(map(str, ans))\n",
    "    valid_pred_df.loc[idx, '1':'16'] = ans\n",
    "score = calc_puzzle(valid_df, valid_pred_df)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b264262-1018-4c40-ad43-b2581acc2e18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60000</th>\n",
       "      <td>TRAIN_60000</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60001</th>\n",
       "      <td>TRAIN_60001</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60002</th>\n",
       "      <td>TRAIN_60002</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60003</th>\n",
       "      <td>TRAIN_60003</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60004</th>\n",
       "      <td>TRAIN_60004</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                ID   1   2   3   4   5   6   7   8  9  10  11  12  13  14  15  \\\n",
       "60000  TRAIN_60000  12  15   9  16   2   7   1   2  6  12   2   8  10   5  14   \n",
       "60001  TRAIN_60001   1  14   7   8   3  10  15   4  2  12   9   5  11  16  13   \n",
       "60002  TRAIN_60002   9  12  15  11   1  15  16   5  1   4  14   4  10   3  14   \n",
       "60003  TRAIN_60003  13   2  11  14  10   3   3  16  6  12   8   1  15   9   7   \n",
       "60004  TRAIN_60004   5   8  14   4  14   4   7   2  6  11  12  15  10  12  13   \n",
       "\n",
       "       16  \n",
       "60000  13  \n",
       "60001   6  \n",
       "60002  13  \n",
       "60003   4  \n",
       "60004   1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172edec3-e7cb-4af9-b0ce-c73745b20ffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 3, 3, 1],\n",
       "       [2, 3, 0, 1],\n",
       "       [1, 2, 3, 1],\n",
       "       [0, 0, 2, 2]], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNT_ROW.argmax(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abd19d2-4d9d-4798-b061-d229fe1e8739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0, 12, 12,  4],\n",
       "       [ 8, 12,  0,  4],\n",
       "       [ 4,  8, 12,  4],\n",
       "       [ 0,  0,  8,  8]], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNT_ROW.argmax(2) * 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb453cde-41ec-4356-8e19-585211cdfc7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 3],\n",
       "       [1, 1, 0, 1],\n",
       "       [0, 3, 0, 2],\n",
       "       [2, 3, 2, 0]], dtype=int64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNT_COL.argmax(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2363d25e-f9e6-44ff-b231-7f4c7c60e7e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1, 14, 15,  7],\n",
       "       [ 9, 13,  0,  5],\n",
       "       [ 4, 11, 12,  6],\n",
       "       [ 2,  3, 10,  8]], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNT_ROW.argmax(2) * 4 + CNT_COL.argmax(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0ea388ae-9d6b-4e80-9c24-f3dbcf990ef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5, 21, 25, 17],\n",
       "       [13, 17,  1,  9],\n",
       "       [ 5, 21, 13, 13],\n",
       "       [ 9, 13, 17,  9]], dtype=int64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNT_ROW.argmax(2) * 4 + CNT_COL.argmax(2) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8971c292-250d-49cf-a0dd-72a8a73141e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e88603b-ad21-4cad-9ebd-ade0f6b9a458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 576)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3e9969d3-6d83-41ca-941e-f07c9448953c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(575//24//6)\n",
    "print(575%24//6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2b51497-dbf0-4b0f-b769-4494558a46c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(0//24//6)\n",
    "print(0%24//6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c071479b-fa09-4cd2-862b-f20694d3a83e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max : 575\n",
      "min : 0\n"
     ]
    }
   ],
   "source": [
    "print(\"max :\",np.max(w))\n",
    "print(\"min :\",np.min(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16c67a50-e98a-42cf-80cd-1ceda6b07296",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (patch_embed): PatchEmbed(\n",
       "    (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "    (norm): Identity()\n",
       "  )\n",
       "  (blocks): Sequential(\n",
       "    (0): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (1): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (2): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (3): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (4): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (5): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (6): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (7): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (8): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (9): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (10): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "    (11): Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (q_norm): Identity()\n",
       "        (k_norm): Identity()\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls1): LayerScale()\n",
       "      (drop_path1): Identity()\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ls2): LayerScale()\n",
       "      (drop_path2): Identity()\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "  (jigsaw): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=768, out_features=576, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a7ca10-f727-4f7b-9f1d-e66090a4c551",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea8756d-1038-49e8-83a7-72691e4c6e70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708964b1-a761-4e1e-83bd-75ffbf3ad1b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8caefc-3ef1-4d3e-b6d0-6c9708b2d89d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7e2242-12c2-4ead-b096-495c55022f3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38e57a4-f3d7-4fbf-b56a-a64dd6c7b55f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
