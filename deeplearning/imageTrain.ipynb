{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07336134-cff1-4c5e-900f-5e271b1bcd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa78f2b9-6083-48f8-b331-8634218109a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mnist\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8533c5e6-dd49-462f-885a-15309d1bd8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Dropout, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48fcd13e-72fb-4368-b476-44ec6677ec1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4a6405-b600-4209-895f-56ea69c2494a",
   "metadata": {},
   "source": [
    "# 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e32f6b7c-48f4-4ec5-8877-cd46ddc0cd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = mnist.train_images()\n",
    "train_labels = mnist.train_labels()\n",
    "test_images = mnist.test_images()\n",
    "test_labels = mnist.test_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41cd8bae-d8f2-47b2-aa78-8f0be3b45829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(train_images.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_images.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0e6604b-a888-43ac-a067-6509ab5a164d",
   "metadata": {},
   "outputs": [],
   "source": [
    "eachImg = pd.DataFrame(train_images[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cce60468-acb8-4743-9e9d-71784ee26117",
   "metadata": {},
   "outputs": [],
   "source": [
    "eachImg.to_csv(\"d:/eachImg.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ece4aed-51f4-4533-b3bf-3b4b69672508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 정규화\n",
    "train_images = (train_images/255)\n",
    "test_images = (test_images/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "91a43bae-75c0-4265-8ce3-f2b5e0d8a18e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "73f91f25-fb70-4283-bb0f-c3c14683c198",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_one_hot = to_categorical(train_labels)\n",
    "test_labels_one_hot = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7c6d19ab-abf0-45f7-aefa-d1208e34b07c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels_one_hot[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0044ad5-dda4-439e-ae92-50e621e00261",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "44c221cd-3b38-4f64-8546-6ea34573bbb2",
   "metadata": {},
   "source": [
    "# 모델생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a92cc893-2a6f-4b59-b66b-a90ca4d93d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input layer를 위한 설정\n",
    "inputShape = train_images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7f573365-bdae-4ec1-a96a-bf5f2dc19575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output layer를 위한 설정\n",
    "nClass = 10\n",
    "nCalss = len(np.unique(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4cf5fa2f-e0b2-4a1a-93c7-67f617061430",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# input layer\n",
    "model.add(Flatten(input_shape = inpuShape))\n",
    "# hidden layer\n",
    "model.add(Dense(units=16, activation=\"relu\"))\n",
    "model.add(Dense(units=16, activation=\"relu\"))\n",
    "# output layer\n",
    "model.add(Dense(units=nCalss, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0436d712-a024-4d67-8789-3f82f6c16260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                12560     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                272       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                170       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,002\n",
      "Trainable params: 13,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5ec1ea2b-5ec4-4b0a-8214-6cf90fc66991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(model, to_file = \"model_plot.png\",\n",
    "           show_shapes=True,\n",
    "           show_layer_names = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac8be1e-1aa0-41e1-b99d-3099fc27e7d5",
   "metadata": {},
   "source": [
    "# 모델 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2608af4d-5aa0-43ac-99a3-173915fcb192",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = \"categorical_crossentropy\",\n",
    "             optimizer = \"adam\",\n",
    "             metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e84493ed-661c-4f99-b733-9e6768ab2eb4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.4825 - accuracy: 0.8562 - val_loss: 0.2565 - val_accuracy: 0.9244\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2526 - accuracy: 0.9265 - val_loss: 0.2227 - val_accuracy: 0.9337\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2149 - accuracy: 0.9371 - val_loss: 0.2097 - val_accuracy: 0.9385\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.1926 - accuracy: 0.9427 - val_loss: 0.1946 - val_accuracy: 0.9413\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.1761 - accuracy: 0.9474 - val_loss: 0.1823 - val_accuracy: 0.9454\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.1634 - accuracy: 0.9512 - val_loss: 0.1749 - val_accuracy: 0.9469\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.1534 - accuracy: 0.9545 - val_loss: 0.1738 - val_accuracy: 0.9488\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.1441 - accuracy: 0.9564 - val_loss: 0.1629 - val_accuracy: 0.9513\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.1376 - accuracy: 0.9581 - val_loss: 0.1779 - val_accuracy: 0.9473\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 2s 1ms/step - loss: 0.1306 - accuracy: 0.9600 - val_loss: 0.1624 - val_accuracy: 0.9520\n"
     ]
    }
   ],
   "source": [
    "hitory = model.fit(x = train_images,\n",
    "                   y = train_labels_one_hot,\n",
    "                   epochs = 10,\n",
    "                   batch_size = 32,\n",
    "                   validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a60c4f7-c2bc-47e0-b779-c88765b28974",
   "metadata": {},
   "source": [
    "### C-1. 모델 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b6054a27-1c3d-490b-ba28-3201921b8ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 1ms/step - loss: 0.1622 - accuracy: 0.9517\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.16220659017562866, 0.95169997215271]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_images, test_labels_one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e589e2-3155-4b37-bff8-06329d8be6fc",
   "metadata": {},
   "source": [
    "### 에측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4b4a1e6f-5d66-4fbe-a6f6-6519feb79dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9881e1-b1d3-4b4c-8fe7-31469067b127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 카톡에서 다운받아서 할것\n",
    "testImg = cv2.imread(\"./img_18.jpg\", cv2.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9d760586-2444-466a-8c3e-b888f458114e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f32f25-296d-4742-9655-e20eb4478519",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(testImg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39b58a4-1fea-461d-8d3c-01d6c7bb2be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f7d989-5228-46d7-b1a4-cc51f9401bc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9066b1b6-919c-4ebb-b688-bcf50c4a29d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237ac26b-978f-4359-94e9-6c5282b3e163",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179c3b3b-8bcc-4619-a5cf-c3bad83ccc61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4488c512-4887-477a-98fb-134e913179ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4590ad8b-e853-4993-86a1-d15fca06aa5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d470262-4e9a-491a-b4d9-c5883093440f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
